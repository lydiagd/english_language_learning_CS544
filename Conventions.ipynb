{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obiTALnwMHeQ",
        "outputId": "acad4c8b-c978-4477-a024-9c91535bd67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYP7vVdAMHeT",
        "outputId": "d218fc70-7e75-4728-f665-9b217efca643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install bs4 # in case you don't have it installed\n",
        "\n",
        "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaU7ypb-MHeU"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Znq__eKMHeV",
        "outputId": "115a8c7a-1723-4c5e-9a6f-14e492c614b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To run on Google Colab: \n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv', usecols=['full_text', 'conventions'], dtype={'full_text': 'object', 'conventions': 'object'}\n",
        "                 )   \n"
      ],
      "metadata": {
        "id": "zNTFz9pSMs7h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['conventions'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KvTvEKON56B",
        "outputId": "b61a5e61-1199-4099-9fb2-8280ecd07785"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       3.0\n",
            "1       2.5\n",
            "2       2.5\n",
            "3       5.0\n",
            "4       2.5\n",
            "       ... \n",
            "3906    2.5\n",
            "3907    3.0\n",
            "3908    3.0\n",
            "3909    4.5\n",
            "3910    3.5\n",
            "Name: conventions, Length: 3911, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlvSd6SwMHeb"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eAXhUzq0MHec"
      },
      "outputs": [],
      "source": [
        "# Convert all reviews to lowercase\n",
        "# random_reviews_5_stars['review_body'] = random_reviews_5_stars['review_body'].str.lower()\n",
        "# random_reviews_4_stars['review_body'] = random_reviews_4_stars['review_body'].str.lower()\n",
        "# random_reviews_3_stars['review_body'] = random_reviews_3_stars['review_body'].str.lower()\n",
        "# random_reviews_2_stars['review_body'] = random_reviews_2_stars['review_body'].str.lower()\n",
        "# random_reviews_1_stars['review_body'] = random_reviews_1_stars['review_body'].str.lower()\n",
        "\n",
        "df['full_text'] = df['full_text'].str.lower() \n",
        "\n",
        "\n",
        "# Check the output \n",
        "# print(random_reviews_5_stars['review_body'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hBjYRjaEMHec"
      },
      "outputs": [],
      "source": [
        "# Remove the HTML and URLs from the reviews \n",
        "# def remove_HTML_URLS(sentence):\n",
        "#     sentence = str(sentence)\n",
        "#     soup = BeautifulSoup(sentence)\n",
        "#     clean_sentence = soup.get_text()\n",
        "#     return clean_sentence \n",
        "\n",
        "# # random_reviews_5_stars['review_body'].apply(remove_HTML_URLS)\n",
        "# # random_reviews_4_stars['review_body'].apply(remove_HTML_URLS)\n",
        "# # random_reviews_3_stars['review_body'].apply(remove_HTML_URLS)\n",
        "# # random_reviews_2_stars['review_body'].apply(remove_HTML_URLS)\n",
        "# # random_reviews_1_stars['review_body'].apply(remove_HTML_URLS)\n",
        "# only_selected_datasets_combined['review_body'] = only_selected_datasets_combined['review_body'].apply(remove_HTML_URLS)\n",
        "\n",
        "\n",
        "# print(random_reviews_5_stars.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "N1FK9dUvMHec"
      },
      "outputs": [],
      "source": [
        "# Remove non-alphabetical characters\n",
        "\n",
        "import re \n",
        "def remove_non_alphabetical_words(sentence):\n",
        "    sentence = str(sentence)\n",
        "    removed_non_alphabetical_words_sentence = re.sub(r'[^a-zA-Z0-9 ]', '', sentence)\n",
        "    return removed_non_alphabetical_words_sentence \n",
        "\n",
        "df['full_text'] = df['full_text'].apply(remove_non_alphabetical_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8F_MtpI-MHed"
      },
      "outputs": [],
      "source": [
        "# Remove extra spaces "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "AQbPy3hUMHed"
      },
      "outputs": [],
      "source": [
        "def remove_extra_spaces(sentence):\n",
        "    sentence = str(sentence)\n",
        "    ' '.join(sentence.split())\n",
        "    removed_extra_spaces_sentence = re.sub(r'[^a-zA-Z0-9 ]', '', sentence)\n",
        "    return removed_extra_spaces_sentence \n",
        "\n",
        "df['full_text'] = df['full_text'].apply(remove_extra_spaces)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrTzLI1kMHed",
        "outputId": "582b05b2-0b72-4f78-cfe7-4c3a718a9c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Install the contractions library\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ymogAjWYMHed"
      },
      "outputs": [],
      "source": [
        "# Perform contractions on the dataframe\n",
        "import contractions\n",
        "\n",
        "def replace_contractions_with_full_words(sentence):\n",
        "    sentence = str(sentence)\n",
        "    replaced_contractions_sentence = contractions.fix(sentence)\n",
        "    return replaced_contractions_sentence \n",
        "\n",
        "df['full_text'] = df['full_text'].apply(replace_contractions_with_full_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cfLq37V4MHee"
      },
      "outputs": [],
      "source": [
        "# # Print the average length of the reviews in terms of character length in your dataset after cleaning\n",
        "# average_length_of_reviews_after_cleaning = only_selected_datasets_combined['review_body'].str.len().mean()\n",
        "# print(average_length_of_reviews_after_cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8KKheSSMHee"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "x_F6nVLQMHee"
      },
      "outputs": [],
      "source": [
        "# Print the average length of the reviews in terms of character length in your dataset before preprocessing\n",
        "# average_length_of_reviews_before_preprocessing = only_selected_datasets_combined['review_body'].str.len().mean()\n",
        "# print(average_length_of_reviews_before_preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8sJ4uNwMHee"
      },
      "source": [
        "## remove the stop words "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTZ81Hb7MHee",
        "outputId": "28a066c5-20a2-4252-a1f9-ed671408ebc7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "# Download the stopwords package. \n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Stop words are only in the review_body column, so remove stop words from this column. \n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stop_words(sentence):  \n",
        "    stopwords_to_remove = stopwords.words('english') # Set the stopwords that will be removed.\n",
        "    sentence = str(sentence)\n",
        "    sentence_list_with_stop_words = sentence.split()\n",
        "    sentence_list_without_stop_words = []\n",
        "    for word in sentence_list_with_stop_words:\n",
        "        if word not in stopwords_to_remove:\n",
        "            sentence_list_without_stop_words.append(word)\n",
        "    sentence_without_stop_words = ' '.join(sentence_list_without_stop_words)\n",
        "    return sentence_without_stop_words\n",
        "    \n",
        "# Apply this function along the review_body axis. \n",
        "# random_reviews_5_stars['review_body'] = random_reviews_5_stars['review_body'].apply(remove_stop_words)\n",
        "# random_reviews_4_stars['review_body'] = random_reviews_4_stars['review_body'].apply(remove_stop_words)\n",
        "# random_reviews_3_stars['review_body'] = random_reviews_3_stars['review_body'].apply(remove_stop_words)\n",
        "# random_reviews_2_stars['review_body'] = random_reviews_2_stars['review_body'].apply(remove_stop_words)\n",
        "# random_reviews_1_stars['review_body'] = random_reviews_1_stars['review_body'].apply(remove_stop_words)\n",
        "df['full_text'] = df['full_text'].apply(remove_stop_words)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GVMH09I5MHef"
      },
      "outputs": [],
      "source": [
        "# Check that output is correct.\n",
        "# print(only_selected_datasets_combined['review_body'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "76dDjtEIMXFw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXAtqtl9MHef"
      },
      "source": [
        "## perform lemmatization  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4AVHS8UMHef",
        "outputId": "7d199fe5-1fcc-4427-ef13-1ce098369c77",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize each word \n",
        "def lemmatize_each_word_in_the_sentence(sentence):  \n",
        "    sentence = str(sentence)\n",
        "    sentence_list_with_words_to_lemmatize = sentence.split() \n",
        "    sentence_list_with_lemmatized_words = []\n",
        "    for word in sentence_list_with_words_to_lemmatize:\n",
        "        lemmatized_word = lemmatizer.lemmatize(word) \n",
        "        sentence_list_with_lemmatized_words.append(lemmatized_word)\n",
        "    sentence_with_lemmatized_words = ' '.join(sentence_list_with_lemmatized_words)\n",
        "    return sentence_with_lemmatized_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lfMIWTq5MHef"
      },
      "outputs": [],
      "source": [
        "# Perform lemmatization.\n",
        "\n",
        "# random_reviews_5_stars['review_body'] = random_reviews_5_stars['review_body'].apply(lemmatize_each_word_in_the_sentence)\n",
        "# random_reviews_4_stars['review_body'] = random_reviews_4_stars['review_body'].apply(lemmatize_each_word_in_the_sentence)\n",
        "# random_reviews_3_stars['review_body'] = random_reviews_3_stars['review_body'].apply(lemmatize_each_word_in_the_sentence)\n",
        "# random_reviews_2_stars['review_body'] = random_reviews_2_stars['review_body'].apply(lemmatize_each_word_in_the_sentence)\n",
        "# random_reviews_1_stars['review_body'] = random_reviews_1_stars['review_body'].apply(lemmatize_each_word_in_the_sentence)\n",
        "df['full_text'] = df['full_text'].apply(lemmatize_each_word_in_the_sentence)\n",
        "\n",
        "\n",
        "# Check \n",
        "# print(random_reviews_5_stars['review_body'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YpxI2EqmVYgX"
      },
      "outputs": [],
      "source": [
        "# Print the average length of the reviews in terms of character length in your dataset after preprocessing\n",
        "# average_length_of_reviews_after_preprocessing = only_selected_datasets_combined['review_body'].str.len().mean()\n",
        "# print(average_length_of_reviews_after_preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjw0f7e-MHeg"
      },
      "source": [
        "# TF-IDF Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jogyKz7EMHeg",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e05cca-409c-4f80-c3c5-1c89d90505fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=92bf7bd5e68e592d18a7e142f9aeb3207e5bc022bd11c8535f7872323baf43d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ],
      "source": [
        "# Install sklearn\n",
        "!pip install sklearn\n",
        "\n",
        "\n",
        "# Import the module\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5bu867RkMHeg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create the vectorizer\n",
        "vectorizer = TfidfVectorizer() \n",
        "train_features_star_rating = vectorizer.fit_transform(df['full_text'].apply(lambda x:np.str_(x))) # convert values to a string along the axis \n",
        "# significance of the words in the corpus \n",
        "# train_features_review_body = vectorizer.fit_transform(df['review_body'].values.astype('U')) # consumes too much memory \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6SYo48uMHeg"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "r5fXLNymMHeg"
      },
      "outputs": [],
      "source": [
        "# Train the Perceptron model on the training dataset using the sklearn built-in implementation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "jo87ELnkMHeg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score \n",
        "\n",
        "# X_labels = vectorizer.get_feature.names_out()\n",
        "Y_values = df['conventions'].values\n",
        "\n",
        "X_training_data, X_testing_data, Y_training_data, Y_testing_data = train_test_split(train_features_star_rating, Y_values, test_size=0.20)\n",
        "\n",
        "\n",
        "perceptron = Perceptron(random_state=40) # choose whatever as long as good result \n",
        "perceptron.fit(X_training_data, Y_training_data)\n",
        "perceptron_score = perceptron.score(X_training_data, Y_training_data)\n",
        "\n",
        "# perceptron.fit(vectorizer.get_feature_names(), Y_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "VOgG3rgLtkhh"
      },
      "outputs": [],
      "source": [
        "# print(perceptron_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adidTozaMHeh",
        "outputId": "213fcef3-9746-47c9-ec41-be130cd2903e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         1.5       0.00      0.00      0.00         4\n",
            "         2.0       0.28      0.22      0.25        86\n",
            "         2.5       0.29      0.28      0.28       148\n",
            "         3.0       0.35      0.33      0.34       246\n",
            "         3.5       0.27      0.29      0.28       174\n",
            "         4.0       0.19      0.21      0.20        91\n",
            "         4.5       0.00      0.00      0.00        26\n",
            "         5.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.27       783\n",
            "   macro avg       0.15      0.15      0.15       783\n",
            "weighted avg       0.28      0.27      0.27       783\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_values = df['full_text'].values\n",
        "predictions_training = perceptron.predict(X_training_data) # must use sparse matrix here with the predict\n",
        "predictions_test = perceptron.predict(X_testing_data)\n",
        "# print(accuracy_score(predictions_training, Y_training_data))\n",
        "# print(accuracy_score(predictions_test, Y_testing_data))\n",
        "\n",
        "# print(accuracy_score(predictions_train, Y_training_data))\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print the classification report \n",
        "print(classification_report(Y_testing_data, predictions_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "VFW2pkZtVN7P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl_IKIy5MHei"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w4hi2IVMHei",
        "outputId": "deddb68d-2b57-403f-f3f3-57dcdb053b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         1.5       0.00      0.00      0.00         4\n",
            "         2.0       0.27      0.12      0.16        86\n",
            "         2.5       0.25      0.28      0.26       148\n",
            "         3.0       0.34      0.42      0.37       246\n",
            "         3.5       0.26      0.33      0.29       174\n",
            "         4.0       0.24      0.15      0.19        91\n",
            "         4.5       0.00      0.00      0.00        26\n",
            "         5.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.29       783\n",
            "   macro avg       0.15      0.14      0.14       783\n",
            "weighted avg       0.27      0.29      0.27       783\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# svm_model = svm.SVR()\n",
        "# svm_model.fit(X_training_data, Y_training_data)\n",
        "linear_svm_model = svm.LinearSVC()\n",
        "linear_svm_model.fit(X_training_data, Y_training_data)\n",
        "\n",
        "# predictions_training_linear_svm = linear_svm_model.predict(X_training_data) # must use sparse matrix here with the predict\n",
        "predictions_test_linear_svm = linear_svm_model.predict(X_testing_data)\n",
        "\n",
        "# Print the classification report \n",
        "print(classification_report(Y_testing_data, predictions_test_linear_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfCS0hFMHei"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyhugkdGMHei",
        "outputId": "d868d2b9-d708-4ade-ecc2-f45ee8aada3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         1.5       0.00      0.00      0.00         4\n",
            "         2.0       0.67      0.05      0.09        86\n",
            "         2.5       0.28      0.26      0.27       148\n",
            "         3.0       0.33      0.57      0.42       246\n",
            "         3.5       0.29      0.35      0.32       174\n",
            "         4.0       0.17      0.02      0.04        91\n",
            "         4.5       0.00      0.00      0.00        26\n",
            "         5.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.31       783\n",
            "   macro avg       0.19      0.14      0.13       783\n",
            "weighted avg       0.32      0.31      0.27       783\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression_model = LogisticRegression(random_state=0, max_iter=1000).fit(X_training_data, Y_training_data)\n",
        "predictions_training_logistic_regression = logistic_regression_model.predict(X_training_data) # must use sparse matrix here with the predict\n",
        "predictions_test_logistic_regression = logistic_regression_model.predict(X_testing_data)\n",
        "\n",
        "# Print the classification report \n",
        "print(classification_report(Y_testing_data, predictions_test_logistic_regression))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCx2kJ2nMHej"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRWGiQ2QMHej",
        "outputId": "ca4d2938-9d3e-4287-bf3f-06c26b17a43c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         1.5       0.00      0.00      0.00         4\n",
            "         2.0       0.00      0.00      0.00        86\n",
            "         2.5       0.00      0.00      0.00       148\n",
            "         3.0       0.31      1.00      0.48       246\n",
            "         3.5       0.00      0.00      0.00       174\n",
            "         4.0       0.00      0.00      0.00        91\n",
            "         4.5       0.00      0.00      0.00        26\n",
            "         5.0       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.31       783\n",
            "   macro avg       0.03      0.11      0.05       783\n",
            "weighted avg       0.10      0.31      0.15       783\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Create the Naive Bayes Model. \n",
        "naive_bayes_model = MultinomialNB()\n",
        "\n",
        "# Train the Naive Bayes Model. \n",
        "naive_bayes_model.fit(X_training_data, Y_training_data)\n",
        "\n",
        "predictions_training_naive_bayes= naive_bayes_model.predict(X_training_data) # must use sparse matrix here with the predict\n",
        "predictions_test_naive_bayes = naive_bayes_model.predict(X_testing_data)\n",
        "\n",
        "# Print the classification report \n",
        "print(classification_report(Y_testing_data, predictions_test_naive_bayes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "L8dEP8YQMHej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a4c8ff-fb0c-45e1-ef66-9f944bf3f400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Generate classification reports for each model, using the predictions from the test data and the Y labels from the test data.\n",
        "# Make the classification report a dictionary with the argument output_dict = True. \n",
        "perceptron_report = classification_report(Y_testing_data, predictions_test, output_dict=True)\n",
        "svm_report = classification_report(Y_testing_data, predictions_test_linear_svm, output_dict=True)\n",
        "logistic_regression_report = classification_report(Y_testing_data, predictions_test_logistic_regression, output_dict=True)\n",
        "naive_bayes_report = classification_report(Y_testing_data, predictions_test_naive_bayes, output_dict=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-3\n",
        "\n",
        "```\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vW_8PLPdAGU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "zDrmmteO_0Lk",
        "outputId": "4f3ac320-f02c-4972-a21e-316479935964"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=056dede07475d6fce7b69ed2ed6ea838e5ebdc84abf137f001ced580fa197a90\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/de/db/e82770b480ec30fd4a6d67108744b9c52be167c04fcf4af7b5\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.2.0.62\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "BIo56JV_Zmua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b79ab55-2499-4876-e283-a6ed8f471f56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-KLLJfeJFomOiNeQFrfzzZHkq at 0x7f5c4c98e890> JSON: {\n",
              "  \"bytes\": 5211623,\n",
              "  \"created_at\": 1669748308,\n",
              "  \"filename\": \"file\",\n",
              "  \"id\": \"file-KLLJfeJFomOiNeQFrfzzZHkq\",\n",
              "  \"object\": \"file\",\n",
              "  \"purpose\": \"classifications\",\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Set credentials\n",
        "secrete_key = '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'\n",
        "openai.api_key = secrete_key\n",
        "\n",
        "# Upload file\n",
        "openai.File.create(file=open(\"/content/drive/My Drive/Colab Notebooks/training.jsonl\"),\n",
        "                   purpose=\"classifications\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = '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'"
      ],
      "metadata": {
        "id": "VNMZ3GixT-rW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "\n",
        "# embedding = openai.Embedding.create(\n",
        "#     input=\"Sample document text goes here\",\n",
        "#     engine=\"text-similarity-davinci-001\"\n",
        "# )[\"data\"][0][\"embedding\"]\n",
        "# len(embedding)"
      ],
      "metadata": {
        "id": "Aa8KVZ7DAOFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_embedding(text: str, engine=\"text-similarity-davinci-001\"):\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    return openai.Embedding.create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n",
        "\n",
        "\n",
        "embedding = get_embedding(\"Sample query text goes here\", engine=\"text-search-ada-query-001\")\n",
        "print(len(embedding))"
      ],
      "metadata": {
        "id": "sWA474GhVZVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9cd226-91ad-43ee-ad14-210f6d733cf8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_1 = df.loc[df['conventions'].isin(['1.0'])]\n",
        "scores_1_5 = df.loc[df['conventions'].isin(['1.5'])]\n",
        "scores_2_5 = df.loc[df['conventions'].isin(['2.5'])].sample(n=50)\n",
        "scores_3 = df.loc[df['conventions'].isin(['3.0'])].sample(n=50)\n",
        "scores_3_5 = df.loc[df['conventions'].isin(['3.5'])].sample(n=50)\n",
        "scores_4 = df.loc[df['conventions'].isin(['4.0'])].sample(n=50)\n",
        "scores_5 = df.loc[df['conventions'].isin(['5.0'])]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R1YDcK_Meoer"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_4_5 = df.loc[df['conventions'].isin(['4.5'])].sample(n=30)"
      ],
      "metadata": {
        "id": "ZDPEH3mos4M4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_2 = df.loc[df['conventions'].isin(['2.0'])].sample(n=50)\n"
      ],
      "metadata": {
        "id": "Gwq5KUrkoaHw"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_1['babbage_similarity'] = scores_1.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uuVBdGOeq3X",
        "outputId": "372843e4-c2c1-484c-f045-785cbdb95dac"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_1_5['babbage_similarity'] = scores_1_5.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6aFxZRZem1R",
        "outputId": "389b17a8-c421-497f-8fb2-2d6a43979064"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_2['babbage_similarity'] = scores_2.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "sUWQIMv4f94M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "d3d1170e-5fb4-4a32-b079-9849114e0331"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RetryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-9f7f9cc30912>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text, engine)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openai/api_resources/embedding.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    180\u001b[0m         )\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 self._interpret_response_line(\n\u001b[0;32m--> 397\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    429\u001b[0m             raise self.handle_error_response(\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-global-with-image-limits in organization org-2b1hpD8fEgpC1MSEioYSs5kd on requests per min. Limit: 60.000000 / min. Current: 66.000000 / min. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://beta.openai.com/account/billing to add a payment method.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-f52ab36bdd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'babbage_similarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'babbage-similarity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-f52ab36bdd44>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'babbage_similarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'babbage-similarity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7f5c4c9cb2d0 state=finished raised RateLimitError>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_2_5['babbage_similarity'] = scores_2_5.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "udzuA6rGf-av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_3['babbage_similarity'] = scores_3.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "4Ka8RnOhf_Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_3_5['babbage_similarity'] = scores_3_5.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "E1aANk0IgD8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_4['babbage_similarity'] = scores_4.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "7Ku-wB2_gKOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_4_5['babbage_similarity'] = scores_4_5.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "2HHIMKGdgLjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_5['babbage_similarity'] = scores_5.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))"
      ],
      "metadata": {
        "id": "cByM42OdgLSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['babbage_similarity'] = df.full_text.apply(lambda x: get_embedding(x, engine='babbage-similarity'))\n",
        "# df.to_csv('output/embedded_newsgroups.csv')\n",
        "\n",
        "### Break up df by score to work with rate limit "
      ],
      "metadata": {
        "id": "Et8xP3FwYxab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "only_selected_datasets_list = [\n",
        "    scores_1,\n",
        "    scores_1_5,\n",
        "    scores_2,\n",
        "    scores_2_5,\n",
        "    scores_3,\n",
        "    scores_3_5,\n",
        "    scores_4,\n",
        "    scores_4_5,\n",
        "    scores_5,\n",
        "    ]\n",
        "\n",
        "only_selected_datasets_combined = pd.concat(only_selected_datasets_list)"
      ],
      "metadata": {
        "id": "tvjtFlFOemV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(only_selected_datasets_combined)"
      ],
      "metadata": {
        "id": "tG8Z9yA4lWNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# datafile_path = \"https://cdn.openai.com/API/examples/data/fine_food_reviews_with_embeddings_1k.csv\"  # for your convenience, we precomputed the embeddings\n",
        "# df = pd.read_csv(datafile_path)\n",
        "# df[\"babbage_similarity\"] = df.babbage_similarity.apply(eval).apply(np.array)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    list(only_selected_datasets_combined.babbage_similarity.values), only_selected_datasets_combined.conventions, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "probas = clf.predict_proba(X_test)\n",
        "\n",
        "report = classification_report(y_test, preds)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "8Mpm5X6AY84T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}